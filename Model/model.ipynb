{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 553361,
     "status": "ok",
     "timestamp": 1770373544578,
     "user": {
      "displayName": "Kirill Strelkov",
      "userId": "18113296526703007272"
     },
     "user_tz": -180
    },
    "id": "ENkI90WqcYUI",
    "outputId": "93c1356c-1b0b-4943-bac9-b82b5a86148b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
      "Requirement already satisfied: split-folders in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.2)\n",
      "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2026.1.4)\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
      "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
      "‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã (Colab –∏—Ö —É–¥–∞–ª–∏–ª). –°–∫–∞—á–∏–≤–∞—é –∑–∞–Ω–æ–≤–æ...\n",
      "Dataset URL: https://www.kaggle.com/datasets/emmarex/plantdisease\n",
      "Downloading plantdisease.zip to ./plantdisease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 658M/658M [00:05<00:00, 117MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –ò—Å—Ö–æ–¥–Ω–∏–∫–∏ –Ω–∞–π–¥–µ–Ω—ã –≤: plantdisease/PlantVillage\n",
      "–†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ train/val...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 20639 files [00:03, 6268.99 files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –î–∞–Ω–Ω—ã–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!\n",
      "‚öôÔ∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: cuda\n",
      "üìÇ –ó–∞–≥—Ä—É–∂–∞—é –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç—å...\n",
      "‚úÖ –ù–∞–π–¥–µ–Ω–æ –∫–ª–∞—Å—Å–æ–≤: 15\n",
      "üß† –ì–æ—Ç–æ–≤–∏–º ResNet18...\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:01<00:00, 44.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø (5 —ç–ø–æ—Ö)...\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 1/5\n",
      "----------\n",
      "train Loss: 0.5086 Acc: 0.8616\n",
      "val Loss: 0.0985 Acc: 0.9741\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 2/5\n",
      "----------\n",
      "train Loss: 0.0976 Acc: 0.9735\n",
      "val Loss: 0.0550 Acc: 0.9855\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 3/5\n",
      "----------\n",
      "train Loss: 0.0550 Acc: 0.9865\n",
      "val Loss: 0.0410 Acc: 0.9886\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 4/5\n",
      "----------\n",
      "train Loss: 0.0383 Acc: 0.9907\n",
      "val Loss: 0.0361 Acc: 0.9903\n",
      "\n",
      "–≠–ø–æ—Ö–∞ 5/5\n",
      "----------\n",
      "train Loss: 0.0259 Acc: 0.9945\n",
      "val Loss: 0.0292 Acc: 0.9927\n",
      "\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω—è—é –º–æ–¥–µ–ª—å...\n",
      "–ì–æ—Ç–æ–≤–æ! –§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: /content/drive/MyDrive/ML_Project_Plants\n"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets split-folders\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import shutil\n",
    "import splitfolders\n",
    "import opendatasets as od\n",
    "from google.colab import drive\n",
    "\n",
    "# --- 1. –ü–†–û–í–ï–†–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ---\n",
    "DATA_DIR = 'dataset'\n",
    "RAW_DATA_DIR = 'plantdisease'\n",
    "\n",
    "if not os.path.exists(os.path.join(DATA_DIR, 'train')):\n",
    "\n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –∫–ª—é—á–∞\n",
    "    if not os.path.exists('kaggle.json'):\n",
    "        print(\" –û–®–ò–ë–ö–ê: –ù–µ—Ç —Ñ–∞–π–ª–∞ kaggle.json! –ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –µ–≥–æ –≤ —Ñ–∞–π–ª—ã —Å–ª–µ–≤–∞.\")\n",
    "    else:\n",
    "        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ\n",
    "        od.download(\"https://www.kaggle.com/datasets/emmarex/plantdisease\")\n",
    "\n",
    "        # –ü–æ–∏—Å–∫ —Å–∫–∞—á–∞–Ω–Ω–æ–π –ø–∞–ø–∫–∏ (–æ–Ω–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –≤–ª–æ–∂–µ–Ω–Ω–æ–π)\n",
    "        input_folder = \"plantdisease/PlantVillage\"\n",
    "        if not os.path.exists(input_folder):\n",
    "            # –ò—â–µ–º –ø–∞–ø–∫—É, –µ—Å–ª–∏ –ø—É—Ç—å –¥—Ä—É–≥–æ–π\n",
    "            for root, dirs, files in os.walk(\".\"):\n",
    "                if \"Tomato_Healthy\" in dirs:\n",
    "                    input_folder = root\n",
    "                    break\n",
    "        splitfolders.ratio(input_folder, output=DATA_DIR, seed=1337, ratio=(0.8, 0.2))\n",
    "\n",
    "# --- 2. –ù–ê–°–¢–†–û–ô–ö–ò –°–û–•–†–ê–ù–ï–ù–ò–Ø ---\n",
    "if not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "PROJECT_PATH = '/content/drive/MyDrive/ML_Project_Plants'\n",
    "SAVE_PATH = f'{PROJECT_PATH}/my_plant_model.pth'\n",
    "CLASSES_PATH = f'{PROJECT_PATH}/classes.txt'\n",
    "os.makedirs(PROJECT_PATH, exist_ok=True)\n",
    "\n",
    "# --- 3. –û–ë–£–ß–ï–ù–ò–ï ---\n",
    "def run_training():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
    "                      for x in ['train', 'val']}\n",
    "\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True)\n",
    "                   for x in ['train', 'val']}\n",
    "\n",
    "    class_names = image_datasets['train'].classes\n",
    "\n",
    "    # –ú–æ–¥–µ–ª—å\n",
    "    print(\"–ì–æ—Ç–æ–≤–∏–º ResNet18...\")\n",
    "    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "    model.fc = nn.Linear(model.fc.in_features, len(class_names))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    print(\"\\nSTART LEARNING\")\n",
    "\n",
    "    for epoch in range(5):\n",
    "        print(f'\\nEpoch {epoch+1}/5')\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "    torch.save(model.state_dict(), SAVE_PATH)\n",
    "    with open(CLASSES_PATH, \"w\") as f:\n",
    "        f.write(\"\\n\".join(class_names))\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫\n",
    "if __name__ == \"__main__\":\n",
    "    run_training()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNdm90EpFJUCXRyvw7Mgf2k",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
